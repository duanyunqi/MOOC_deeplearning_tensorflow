{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、项目简介\n",
    "猫狗大战来源于Kaggle上的一个竞赛，利用给定的数据集，用算法实现猫和狗的识别。  \n",
    "\n",
    "数据集由训练数据和测试数据组成：\n",
    "\n",
    "    训练数据包含猫和狗各12500张图片；  \n",
    "    测试数据包含12500张猫和狗的图片；\n",
    "    \n",
    "数据集下载链接：https://www.kaggle.com/c/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、项目流程：\n",
    "\n",
    "### 1 数据准备\n",
    "\n",
    "### 2 VGG16的Tensorflow实现\n",
    "    定义功能函数\n",
    "    定义VGG16模型类\n",
    "### 3 VGG16模型复用\n",
    "    微调  \n",
    "    载入权重\n",
    "### 4 数据输入\n",
    "### 5 模型重新训练与保存\n",
    "### 6 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、代码示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、定义功能函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "def conv(self, name, input_data, out_channel, trainable=False): # trainable参数变动\n",
    "    in_channel = input_data.get_shape()[-1]\n",
    "    with tf.variable_scope(name):\n",
    "        kernel = tf.get_variable('weights', [3, 3, in_channel, out_channel], \n",
    "                                 dtype=tf.float32, trainable=False)\n",
    "        biases = tf.get_variable('biases', [out_channel], \n",
    "                                 dtype=tf.float32, trainable=False)\n",
    "        conv_res = tf.nn.conv2d(input_data, kernel, [1,1,1,1], padding='SAME')\n",
    "        res = tf.nn.bias_add(conv_res, biases)\n",
    "        out = tf.nn.relu(res, name=name)  \n",
    "    self.parameters += [kernel, biases] # 将卷积层定义的参数加入列表\n",
    "    return out\n",
    "\n",
    "# 全连接层\n",
    "def fc(self, name, input_data, out_channel, trainable=False):\n",
    "    shape = input_data.get_shape().as_list()\n",
    "    if len(shape)==4:\n",
    "        size =  shape[-1] * shape[-2] * shape[-3]\n",
    "    else:\n",
    "        size=shape[1]\n",
    "    input_data_flat = tf.reshape(input_data, [-1, size])\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable(name='weights', shape=[size, out_channel], \n",
    "                                  dtype=tf.float32, trainable=False)\n",
    "        biases = tf.get_variable(name='biases', shape=[out_channel],\n",
    "                                 dtype=tf.float32, trainable=False)\n",
    "        res = tf.matmul(input_data_flat, weights)\n",
    "        out = tf.nn.relu(tf.nn.bias_add(res, biases))\n",
    "    self.parameters += [weights, biases] # 将全连接层定义的参数加入列表    \n",
    "    return out\n",
    "\n",
    "def maxpool(self, name, input_data):\n",
    "    out = tf.nn.max_pool(input_data, [1,2,2,1], [1,2,2,1], \n",
    "                         padding='SAME', name=name)\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、定义VGG-16模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16:\n",
    "    def __init__(self, imgs):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "        self.fc_layers()\n",
    "        self.probs=self.fc8\n",
    "        \n",
    "    def fc_layers(self):\n",
    "        self.fc6 = self.fc('fc1', self.pool5, 4096, trainable=False)\n",
    "        self.fc7 = self.fc('fc2', self.fc6, 4096, trainable=False)\n",
    "        self.fc8 = self.fc('fc3', self.fc7, n_class, trainable=True)\n",
    "        # fc8是我们需要训练的trainable=True，2是n_class\n",
    "        \n",
    "    def convlayers(self):\n",
    "        # conv1\n",
    "        self.conv1_1 = self.conv('conv1re_1', self.imgs, 64, trainable=False)\n",
    "        self.conv1_2 = self.conv('conv1_2', self.conv1_1, 64, trainable=False)\n",
    "        self.pool1 = self.maxpool('poolre1', self.conv1_2)\n",
    "        \n",
    "        # conv2\n",
    "        self.conv2_1 = self.conv('conv2_1', self.pool1, 128, trainable=False)\n",
    "        self.conv2_2 = self.conv('conv2_2', self.conv2_1, 128, trainable=False)\n",
    "        self.pool2 = self.maxpool('pool2', self.conv2_2)\n",
    "        \n",
    "        # conv3\n",
    "        self.conv3_1 = self.conv('conv3_1', self.pool2, 256, trainable=False)\n",
    "        self.conv3_2 = self.conv('conv3_2', self.conv3_1, 256, trainable=False)\n",
    "        self.conv3_3 = self.conv('conv3_3', self.conv3_2, 256, trainable=False)\n",
    "        self.pool3 = self.maxpool('pool3', self.conv3_3)\n",
    "        \n",
    "        # conv4\n",
    "        self.conv4_1 = self.conv('conv4_1', self.pool3, 512, trainable=False)\n",
    "        self.conv4_2 = self.conv('conv4_2', self.conv4_1, 512, trainable=False)\n",
    "        self.conv4_3 = self.conv('conv4_3', self.conv4_2, 512, trainable=False)\n",
    "        self.pool4 = self.conv('pool4', self.conv4_3)\n",
    "        \n",
    "        # conv5\n",
    "        self.conv5_1 = self.conv('conv5_1', self.pool4, 512, trainable=False)\n",
    "        self.conv5_2 = self.conv('conv5_2', self.conv5_1, 512, trainable=False)\n",
    "        self.conv5_3 = self.conv('conv5_3', self.conv5_2, 512, trainable=False)\n",
    "        self.pool5 = self.conv('pool5', self.conv5_3)\n",
    "        \n",
    "        \n",
    "        # 载入权重\n",
    "        def load_weights(self, weight_file, sess): # 这个函数将获取的权重载入VGG模型中\n",
    "            weights = np.load(weight_file) \n",
    "            keys = sorted(weights.keys())\n",
    "            for i, k in enumerate(keys):\n",
    "                if i not in [30, 31]: # 剔除不需载入的层\n",
    "                    sess.run(self.parameters[i].assign(weights[k]))\n",
    "            print('-------------weights loaded-------------')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、数据输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(file_dir):\n",
    "    images = []\n",
    "    temp = []\n",
    "    for root, sub_folders, files in os.walk(file_dir):\n",
    "        for name in files:\n",
    "            images.append(os.path.join(root, name))\n",
    "        for name in sub_folders:\n",
    "            temp.append(os.path.join(root, name))\n",
    "            labels = []\n",
    "    for one_folder in temp:\n",
    "        n_img = len(os.listdir(one_folder))\n",
    "        letter = one_folder.split('/')[-1]\n",
    "        if letter == 'cat':\n",
    "            labels = np.append(labels, n_img * [0])\n",
    "        else:\n",
    "            labels = np.append(labels, n_img * [1])\n",
    "            \n",
    "    # shuffle\n",
    "    temp = np.array([images, labels])\n",
    "    temp = temp.transpose()\n",
    "    np.random.shuffle(temp)\n",
    "    image_list = list(temp[:,0])\n",
    "    label_list = list(temp[:,1])\n",
    "    label_list = [int(float(i)) for i in label_list]\n",
    "    \n",
    "    return image_list, label_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_preprocess import preprocess_for_train\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "def get_batch(image_list, label_list, \n",
    "              img_width, img_height, \n",
    "              batch_size, capacity):# 通过读取列表来载入批量图片及标签\n",
    "    image = tf.cast(image_list, tf.string)\n",
    "    label = tf.cast(label_list, tf.int32)\n",
    "    input_queue = tf.train.slice_input_producer([image, label])\n",
    "    label = input_queue[1]\n",
    "    image_contents = tf.read_file(input_queue[0])\n",
    "    \n",
    "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "    image = preprocess_for_train(image, 224, 224)\n",
    "    image_batch, label_batch = tf.train.batch([image, label], \n",
    "                                              batch_size=batch_size,\n",
    "                                              num_threads=64,\n",
    "                                              capacity=capacity)\n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "    \n",
    "    return image_batch, label_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4、标签格式的重构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(labels):\n",
    "    n_sample = len(labels)\n",
    "    n_class = max(labels) + 1\n",
    "    onehot_labels = np.zeros((n_sample, n_class))\n",
    "    onehot_labels[np.arange(n_sample), labels] = 1\n",
    "    return onehot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、模型重新训练与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from time import time\n",
    "import VGG16_model as model\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time()\n",
    "batch_size = 32\n",
    "capacity = 256 # 内存中存储的最大数据容量\n",
    "means = [123.68, 116.779, 103.939] # VGG训练时图像预处理所减均值（RGB三通道）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = utils.get_file('./data/train')# 获取图像列表与标签列表\n",
    "# 通过读取列表来载入批量图片和标签\n",
    "image_batch, label_batch = utils.get_batch(xs, ys, 224, 224, \n",
    "                                           batch_size, capacity)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "y = tf.placeholder(tf.int32, [None, 2])# 对猫和狗两个类别进行判定\n",
    "\n",
    "vgg = model.vgg16(x)\n",
    "fc8_finetuining = vgg.probs # 即softmax(fc8) # 微调\n",
    "loss_function = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=fc8_finetuining, labels=y))# 损失函数\n",
    "# 优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 通过npz格式的文件获取VGG的相应权重参数，从而将权重注入即可实现复用\n",
    "vgg.load_weights('./vgg16/vgg16_weights.npz', sess)\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator() # 使用协调器Coordinator来管理线程\n",
    "threads = tf.train.start_queue_runners(coord=coord,sess=sess)# 启动线程\n",
    "epoch_start_time = time()\n",
    "\n",
    "# 迭代训练\n",
    "for i in range(1000):\n",
    "    images, labels = sess.run([image_batch, label_batch])\n",
    "    labels = utils.onehot(labels) # 用one-hot形式对标签进行编码\n",
    "    \n",
    "    sess.run(optimizer, feed_dict={x:images, y:labels})\n",
    "    loss = sess.run(loss_function, feed_dict={x:images, y:labels})\n",
    "    print('Now the loss is %f' % loss)\n",
    "    \n",
    "    epoch_end_time = time\n",
    "    print('Current epoch takes:', (epoch_end_time - epoch_start_time))\n",
    "    epoch_start_time = epoch_end_time\n",
    "    \n",
    "    if (i+1) % 500 == 0:\n",
    "        saver.save(sess, os.path.join('./model/', 'epoch_{:06d}.ckpt'.format(i)))\n",
    "        \n",
    "    print('-----------Epoch %d is finished----------'% i)\n",
    "\n",
    "# 模型保存\n",
    "saver.save(sess, './model/')\n",
    "print('Optimization Finished!')\n",
    "\n",
    "# 关闭线程\n",
    "coord.request_stop()# 通知其他线程关闭\n",
    "coord.join(threads)# join操作等待其他线程结束，其他所有线程关闭之后，这一函数才能返回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [123.68, 116.779, 103.939]\n",
    "x = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "\n",
    "sess = tf.Session()\n",
    "vgg = model.vgg16(x)\n",
    "fc8_finetuining = vgg.probs\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "print('Model restoring...')\n",
    "saver.restore(sess, './model/')# 恢复最后保存的模型\n",
    "# saver.restore(sess, './model/epoch_000800.ckpt')# 恢复指定检查点的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './data/test/21.jpg' # 狗的图片\n",
    "img = imread(filepath, mode='RGB')\n",
    "img = imresize(img, (224, 224))\n",
    "img = img.astype(np.float32)\n",
    "for c in range(3):\n",
    "    img[:,:,c] -= mean[c]\n",
    "prob = sess.run(fc8_finetuining, feed_dict={x:[img]})\n",
    "max_index = np.argmax(prob)\n",
    "\n",
    "if max_index == 0:\n",
    "    print('This is a cat with possibility %.6f' % prob[:,0])\n",
    "else:\n",
    "    print('This is a dog with possibility %.6f' % prob[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1] *",
   "language": "python",
   "name": "conda-env-tensorflow1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
